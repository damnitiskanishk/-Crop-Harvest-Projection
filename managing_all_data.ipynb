{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(r\"C:\\Users\\Kanishk Goyal\\OneDrive - IIT Kanpur\\Desktop\\Prof. Hamim Zafar\\Data\\Regridding Data\\soil_temp_lvl1_08-19_3-4.csv\")\n",
    "df_2 = pd.read_csv(r\"C:\\Users\\Kanishk Goyal\\OneDrive - IIT Kanpur\\Desktop\\Prof. Hamim Zafar\\Data\\Regridding Data\\soil_temp_lvl2_08-19_3-4.csv\")\n",
    "df_3 = pd.read_csv(r\"C:\\Users\\Kanishk Goyal\\OneDrive - IIT Kanpur\\Desktop\\Prof. Hamim Zafar\\Data\\Regridding Data\\soil_temp_lvl3_08-19_3-4.csv\")\n",
    "df_4 = pd.read_csv(r\"C:\\Users\\Kanishk Goyal\\OneDrive - IIT Kanpur\\Desktop\\Prof. Hamim Zafar\\Data\\Regridding Data\\soil_temp_lvl4_08-19_3-4.csv\")\n",
    "\n",
    "df_5 = pd.read_csv(r\"C:\\Users\\Kanishk Goyal\\OneDrive - IIT Kanpur\\Desktop\\Prof. Hamim Zafar\\Data\\Regridding Data\\soil_water_lvl1_08-19_3-4.csv\")\n",
    "df_6 = pd.read_csv(r\"C:\\Users\\Kanishk Goyal\\OneDrive - IIT Kanpur\\Desktop\\Prof. Hamim Zafar\\Data\\Regridding Data\\soil_water_lvl2_08-19_3-4.csv\")\n",
    "df_7 = pd.read_csv(r\"C:\\Users\\Kanishk Goyal\\OneDrive - IIT Kanpur\\Desktop\\Prof. Hamim Zafar\\Data\\Regridding Data\\soil_water_lvl3_08-19_3-4.csv\")\n",
    "df_8 = pd.read_csv(r\"C:\\Users\\Kanishk Goyal\\OneDrive - IIT Kanpur\\Desktop\\Prof. Hamim Zafar\\Data\\Regridding Data\\soil_water_lvl4_08-19_3-4.csv\")\n",
    "\n",
    "df_9 = pd.read_csv(r\"C:\\Users\\Kanishk Goyal\\OneDrive - IIT Kanpur\\Desktop\\Prof. Hamim Zafar\\Data\\Regridding Data\\precipitation_08-19_3-4.csv\")\n",
    "\n",
    "df_10 = pd.read_csv(r\"C:\\Users\\Kanishk Goyal\\OneDrive - IIT Kanpur\\Desktop\\Prof. Hamim Zafar\\Data\\Regridding Data\\solar_radiation_08-19_3-4.csv\")\n",
    "\n",
    "df_11 = pd.read_csv(r\"C:\\Users\\Kanishk Goyal\\OneDrive - IIT Kanpur\\Desktop\\Prof. Hamim Zafar\\Data\\Regridding Data\\temp_08-19_3-4.csv\")\n",
    "\n",
    "\n",
    "df_12 = pd.read_csv(r\"C:\\Users\\Kanishk Goyal\\OneDrive - IIT Kanpur\\Desktop\\Prof. Hamim Zafar\\Data\\Regridding Data\\soil_temp_lvl1_97-07_3-4.csv\")\n",
    "df_13 = pd.read_csv(r\"C:\\Users\\Kanishk Goyal\\OneDrive - IIT Kanpur\\Desktop\\Prof. Hamim Zafar\\Data\\Regridding Data\\soil_temp_lvl2_97-07_3-4.csv\")\n",
    "df_14 = pd.read_csv(r\"C:\\Users\\Kanishk Goyal\\OneDrive - IIT Kanpur\\Desktop\\Prof. Hamim Zafar\\Data\\Regridding Data\\soil_temp_lvl3_97-07_3-4.csv\")\n",
    "df_15 = pd.read_csv(r\"C:\\Users\\Kanishk Goyal\\OneDrive - IIT Kanpur\\Desktop\\Prof. Hamim Zafar\\Data\\Regridding Data\\soil_temp_lvl4_97-07_3-4.csv\")\n",
    "\n",
    "df_16 = pd.read_csv(r\"C:\\Users\\Kanishk Goyal\\OneDrive - IIT Kanpur\\Desktop\\Prof. Hamim Zafar\\Data\\Regridding Data\\soil_water_lvl1_97-07_3-4.csv\")\n",
    "df_17 = pd.read_csv(r\"C:\\Users\\Kanishk Goyal\\OneDrive - IIT Kanpur\\Desktop\\Prof. Hamim Zafar\\Data\\Regridding Data\\soil_water_lvl2_97-07_3-4.csv\")\n",
    "df_18 = pd.read_csv(r\"C:\\Users\\Kanishk Goyal\\OneDrive - IIT Kanpur\\Desktop\\Prof. Hamim Zafar\\Data\\Regridding Data\\soil_water_lvl3_97-07_3-4.csv\")\n",
    "df_19 = pd.read_csv(r\"C:\\Users\\Kanishk Goyal\\OneDrive - IIT Kanpur\\Desktop\\Prof. Hamim Zafar\\Data\\Regridding Data\\soil_water_lvl4_97-07_3-4.csv\")\n",
    "\n",
    "df_20 = pd.read_csv(r\"C:\\Users\\Kanishk Goyal\\OneDrive - IIT Kanpur\\Desktop\\Prof. Hamim Zafar\\Data\\Regridding Data\\precipitation_97-07_3-4.csv\")\n",
    "\n",
    "df_21 = pd.read_csv(r\"C:\\Users\\Kanishk Goyal\\OneDrive - IIT Kanpur\\Desktop\\Prof. Hamim Zafar\\Data\\Regridding Data\\solar_radiation_97-07_3-4.csv\")\n",
    "\n",
    "df_22 = pd.read_csv(r\"C:\\Users\\Kanishk Goyal\\OneDrive - IIT Kanpur\\Desktop\\Prof. Hamim Zafar\\Data\\Regridding Data\\temp_08-19_3-4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.drop(columns=['Unnamed: 0'])\n",
    "df_2 = df_2.drop(columns=['Unnamed: 0'])\n",
    "df_3 = df_3.drop(columns=['Unnamed: 0'])\n",
    "df_4 = df_4.drop(columns=['Unnamed: 0'])\n",
    "df_5 = df_5.drop(columns=['Unnamed: 0'])\n",
    "df_6 = df_6.drop(columns=['Unnamed: 0'])\n",
    "df_7 = df_7.drop(columns=['Unnamed: 0'])\n",
    "df_8 = df_8.drop(columns=['Unnamed: 0'])\n",
    "df_9 = df_9.drop(columns=['Unnamed: 0'])\n",
    "df_10 = df_10.drop(columns=['Unnamed: 0'])\n",
    "df_11 = df_11.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df_12 = df_12.drop(columns=['Unnamed: 0'])\n",
    "df_13 = df_13.drop(columns=['Unnamed: 0'])\n",
    "df_14 = df_14.drop(columns=['Unnamed: 0'])\n",
    "df_15 = df_15.drop(columns=['Unnamed: 0'])\n",
    "df_16 = df_16.drop(columns=['Unnamed: 0'])\n",
    "df_17 = df_17.drop(columns=['Unnamed: 0'])\n",
    "df_18 = df_18.drop(columns=['Unnamed: 0'])\n",
    "df_19 = df_19.drop(columns=['Unnamed: 0'])\n",
    "df_20 = df_20.drop(columns=['Unnamed: 0'])\n",
    "df_21 = df_21.drop(columns=['Unnamed: 0'])\n",
    "df_22 = df_22.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.concat([df_1, df_12], ignore_index=True)\n",
    "df2 = pd.concat([df_2, df_13], ignore_index=True)\n",
    "df3 = pd.concat([df_3, df_14], ignore_index=True)\n",
    "df4 = pd.concat([df_4, df_15], ignore_index=True)\n",
    "df5 = pd.concat([df_5, df_16], ignore_index=True)\n",
    "df6 = pd.concat([df_6, df_17], ignore_index=True)\n",
    "df7 = pd.concat([df_7, df_18], ignore_index=True)\n",
    "df8 = pd.concat([df_8, df_19], ignore_index=True)\n",
    "df9 = pd.concat([df_9, df_20], ignore_index=True)\n",
    "df10 = pd.concat([df_10, df_21], ignore_index=True)\n",
    "df11 = pd.concat([df_11, df_22], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df1, df2, on=['latitude', 'longitude', 'year'], how='outer')\n",
    "df = pd.merge(df, df3, on=['latitude', 'longitude', 'year'], how='outer')\n",
    "df = pd.merge(df, df4, on=['latitude', 'longitude', 'year'], how='outer')\n",
    "df = pd.merge(df, df5, on=['latitude', 'longitude', 'year'], how='outer')\n",
    "df = pd.merge(df, df6, on=['latitude', 'longitude', 'year'], how='outer')\n",
    "df = pd.merge(df, df7, on=['latitude', 'longitude', 'year'], how='outer')\n",
    "df = pd.merge(df, df8, on=['latitude', 'longitude', 'year'], how='outer')\n",
    "df = pd.merge(df, df9, on=['latitude', 'longitude', 'year'], how='outer')\n",
    "df = pd.merge(df, df10, on=['latitude', 'longitude', 'year'], how='outer')\n",
    "#df = pd.merge(df, df11, on=['latitude', 'longitude', 'year'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_district = pd.read_csv(r\"C:\\Users\\Kanishk Goyal\\OneDrive - IIT Kanpur\\Desktop\\Prof. Hamim Zafar\\Data\\centroid_lat_lon.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_district.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_district.rename(columns={'Latitude':'latitude' , 'Longitude':'longitude'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round latitude and longitude in df2 to 6 decimal places\n",
    "df_district['latitude_rounded'] = df_district['latitude'].round(6)\n",
    "df_district['longitude_rounded'] = df_district['longitude'].round(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_mapping = dict(zip(zip(df_district['latitude_rounded'], df_district['longitude_rounded']), df_district['DistrictName']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['latitude_rounded'] = df['latitude'].round(6)\n",
    "df['longitude_rounded'] = df['longitude'].round(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_district[['latitude_rounded', 'longitude_rounded']].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[['latitude_rounded', 'longitude_rounded']].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map district_name based on rounded latitude and longitude in df1\n",
    "df['DistrictName'] = df.apply(lambda row: district_mapping.get((row['latitude_rounded'], row['longitude_rounded']), None), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['latitude_rounded','longitude_rounded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to lowercase and remove spaces\n",
    "df['DistrictName'] = df['DistrictName'].astype(str).str.lower().str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yield = pd.read_csv(r\"C:\\Users\\Kanishk Goyal\\OneDrive - IIT Kanpur\\Desktop\\Prof. Hamim Zafar\\Data\\Yield data\\Moong_Yield.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to lowercase and remove spaces\n",
    "df_yield['DistrictName'] = df_yield['DistrictName'].astype(str).str.lower().str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yield['year'] = df_yield['year'].astype(str).str.split('-').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yield.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_yield[['DistrictName', 'year']].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[['DistrictName', 'year']].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['year'] = df['year'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yield['year'] = df_yield['year'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_yield[['DistrictName', 'year']].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yield_mapping = dict(zip(zip(df_yield['DistrictName'], df_yield['year']), df_yield['Yield(tonnes/hectare)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map district_name based on rounded latitude and longitude in df1\n",
    "df['Yield(tonnes/hectare)'] = df.apply(lambda row: yield_mapping.get((row['DistrictName'], row['year']), None ), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r\"C:\\Users\\Kanishk Goyal\\OneDrive - IIT Kanpur\\Desktop\\Prof. Hamim Zafar\\Data\\Final Data\\greengram_97-19.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_nan = (df['Yield(tonnes/hectare)'].isnull().sum() / len(df)) * 100\n",
    "\n",
    "print(f\"Percentage of NaN values in 'Yield(tonnes/hectare)': {percentage_nan:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
